input {
  # Media with all related data
  jdbc {
    type => "media"
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}"
    jdbc_user => "${POSTGRES_USER}"
    jdbc_password => "${POSTGRES_PASSWORD}"
    jdbc_validate_connection => true
    jdbc_validation_timeout => 3600
    jdbc_paging_enabled => true
    jdbc_page_size => 50000
    jdbc_fetch_size => 50000
    schedule => "${SYNC_INTERVAL}"
    statement => "
      SELECT 
        m.id,
        m.title,
        m.originaltitle,
        m.type,
        m.slug,
        m.description,
        m.year,
        m.runtime,
        m.status,
        m.rated,
        m.language,
        m.country,
        m.imdbrating::float as imdb_rating,
        m.imdbvotes::integer as imdb_votes,
        m.metascore::integer,
        m.rottentomatoes::integer as rotten_tomatoes,
        m.poster,
        m.background,
        m.logo,
        m.budget::float,
        m.boxoffice::float as box_office,
        m.totalseasons::integer as total_seasons,
        m.homepage,
        m.tagline,
        m.votecount::integer as vote_count,
        m.spokenlanguages as spoken_languages,
        EXTRACT(EPOCH FROM m.released) as released_timestamp,
        EXTRACT(EPOCH FROM m.createdat) as created_timestamp,
        EXTRACT(EPOCH FROM m.updatedat) as updated_timestamp,
        
        -- Genres as array
        array_to_json(array_agg(DISTINCT g.name)) FILTER (WHERE g.name IS NOT NULL) as genres,
        
        -- Keywords as array
        array_to_json(array_agg(DISTINCT k.name)) FILTER (WHERE k.name IS NOT NULL) as keywords,
        
        -- Production Companies
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'id', pc.id,
          'name', pc.name,
          'origin_country', pc.origincountry
        )) FILTER (WHERE pc.id IS NOT NULL)) as production_companies,
        
        -- Certifications
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'country', c.country,
          'rating', c.rating
        )) FILTER (WHERE c.id IS NOT NULL)) as certifications,
        
        -- Awards
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'name', a.name,
          'category', a.category,
          'year', a.year,
          'is_winner', a.iswinner
        )) FILTER (WHERE a.id IS NOT NULL)) as awards,
        
        -- Cast Members (limited to main cast)
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'character', cm.character,
          'person_name', p.name,
          'person_id', p.id
        )) FILTER (WHERE cm.id IS NOT NULL AND cm.order <= 10)) as main_cast,
        
        -- Directors and Writers
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'name', p2.name,
          'id', p2.id,
          'job', crm.job
        )) FILTER (WHERE crm.id IS NOT NULL AND crm.job IN ('Director', 'Writer'))) as creators
        
      FROM media m
      LEFT JOIN mediagenres mg ON m.id = mg.mediaid
      LEFT JOIN genres g ON mg.genresid = g.id
      LEFT JOIN mediakeywords mk ON m.id = mk.mediaid
      LEFT JOIN keywords k ON mk.keywordsid = k.id
      LEFT JOIN mediaproductioncompanies mpc ON m.id = mpc.mediaid
      LEFT JOIN productioncompanies pc ON mpc.productioncompaniesid = pc.id
      LEFT JOIN mediacertifications mc ON m.id = mc.mediaid
      LEFT JOIN certifications c ON mc.certificationid = c.id
      LEFT JOIN awards a ON m.id = a.mediaid
      LEFT JOIN castmembers cm ON m.id = cm.mediaid
      LEFT JOIN people p ON cm.personid = p.id
      LEFT JOIN crewmembers crm ON m.id = crm.mediaid
      LEFT JOIN people p2 ON crm.personid = p2.id
      WHERE m.updatedat > :sql_last_value
      GROUP BY m.id
      ORDER BY m.updatedat ASC"
    tracking_column => "updated_timestamp"
    tracking_column_type => "numeric"
    use_column_value => true
    clean_run => false
    last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_media"
    connection_retry_attempts => 3
    connection_retry_attempts_wait_time => 10
  }

  # People Index
  jdbc {
    type => "people"
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}"
    jdbc_user => "${POSTGRES_USER}"
    jdbc_password => "${POSTGRES_PASSWORD}"
    jdbc_validate_connection => true
    jdbc_validation_timeout => 3600
    schedule => "${SYNC_INTERVAL}"
    statement => "
      SELECT 
        p.id,
        p.name,
        p.birthname,
        EXTRACT(EPOCH FROM p.birthday) as birthday_timestamp,
        EXTRACT(EPOCH FROM p.deathday) as deathday_timestamp,
        p.gender,
        p.biography,
        p.birthplace,
        p.photo,
        p.popularity::float,
        EXTRACT(EPOCH FROM p.createdat) as created_timestamp,
        EXTRACT(EPOCH FROM p.updatedat) as updated_timestamp,
        
        -- External IDs
        pe.imdb as imdb_id,
        pe.tvdb as tvdb_id,
        pe.moviedb as moviedb_id,
        
        -- Notable works (limited to 10)
        array_to_json(array_agg(DISTINCT jsonb_build_object(
          'media_id', m.id,
          'title', m.title,
          'year', m.year,
          'role', COALESCE(cm.character, crm.job)
        )) FILTER (WHERE m.id IS NOT NULL) ORDER BY m.year DESC LIMIT 10) as notable_works
        
      FROM people p
      LEFT JOIN personexternalids pe ON p.id = pe.personid
      LEFT JOIN castmembers cm ON p.id = cm.personid
      LEFT JOIN crewmembers crm ON p.id = crm.personid
      LEFT JOIN media m ON cm.mediaid = m.id OR crm.mediaid = m.id
      WHERE p.updatedat > :sql_last_value
      GROUP BY p.id, pe.imdb, pe.tvdb, pe.moviedb
      ORDER BY p.updatedat ASC"
    tracking_column => "updated_timestamp"
    tracking_column_type => "numeric"
    use_column_value => true
    clean_run => false
    last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_people"
    connection_retry_attempts => 3
    connection_retry_attempts_wait_time => 10
  }
}

filter {
  # Common processing
  mutate {
    remove_field => ["@version", "@timestamp"]
  }

  # Media-specific processing
  if [type] == "media" {
    json {
      source => "genres"
      target => "genres"
      skip_on_invalid_json => true
    }
    
    json {
      source => "keywords"
      target => "keywords"
      skip_on_invalid_json => true
    }
    
    json {
      source => "production_companies"
      target => "production_companies"
      skip_on_invalid_json => true
    }
    
    json {
      source => "main_cast"
      target => "main_cast"
      skip_on_invalid_json => true
    }
    
    json {
      source => "creators"
      target => "creators"
      skip_on_invalid_json => true
    }

    # Convert arrays to strings for Manticore
    ruby {
      code => '
        def array_to_string(arr)
          return "" if arr.nil?
          arr.compact.join(" | ")
        end

        event.set("genres_string", array_to_string(event.get("genres")))
        event.set("keywords_string", array_to_string(event.get("keywords")))
        
        # Create searchable cast string
        cast = event.get("main_cast")
        if cast
          cast_names = cast.map { |c| c["person_name"] }.compact
          event.set("cast_string", cast_names.join(" | "))
        end

        # Create searchable creators string
        creators = event.get("creators")
        if creators
          creator_names = creators.map { |c| c["name"] }.compact
          event.set("creators_string", creator_names.join(" | "))
        end
      '
    }
  }

  # People-specific processing
  if [type] == "people" {
    json {
      source => "notable_works"
      target => "notable_works"
      skip_on_invalid_json => true
    }

    # Create searchable works string
    ruby {
      code => '
        works = event.get("notable_works")
        if works
          titles = works.map { |w| w["title"] }.compact
          event.set("works_string", titles.join(" | "))
        end
      '
    }
  }
}

output {
  if [type] == "media" {
    http {
      url => "${MANTICORE_URL:http://manticore:9308}/media/replace"
      http_method => "post"
      format => "json"
      content_type => "application/json"
      retry_non_idempotent => true
      retry_failed => true
      pool_max => 100
      pool_max_per_route => 50
      codec => json
      headers => {
        "Content-Type" => "application/json"
        "Authorization" => "${MANTICORE_API_KEY:-}"
      }
    }
    
    # Backup failed documents
    if [@metadata][http_response_code] != 200 {
      file {
        path => "/usr/share/logstash/data/failed_media_%{+yyyy_MM_dd}.log"
        codec => json
      }
    }
  }
  
  if [type] == "people" {
    http {
      url => "${MANTICORE_URL:http://manticore:9308}/people/replace"
      http_method => "post"
      format => "json"
      content_type => "application/json"
      retry_non_idempotent => true
      retry_failed => true
      pool_max => 100
      pool_max_per_route => 50
      codec => json
      headers => {
        "Content-Type" => "application/json"
        "Authorization" => "${MANTICORE_API_KEY:-}"
      }
    }
    
    # Backup failed documents
    if [@metadata][http_response_code] != 200 {
      file {
        path => "/usr/share/logstash/data/failed_people_%{+yyyy_MM_dd}.log"
        codec => json
      }
    }
  }

  # Debug output (optional, comment out in production)
  # stdout { codec => rubydebug }
}
